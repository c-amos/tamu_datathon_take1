{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>country_code</th>\n",
       "      <th>crop_land</th>\n",
       "      <th>grazing_land</th>\n",
       "      <th>fishing_ground</th>\n",
       "      <th>built_up_land</th>\n",
       "      <th>carbon</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>72186.000000</td>\n",
       "      <td>72186.000000</td>\n",
       "      <td>5.171400e+04</td>\n",
       "      <td>5.171400e+04</td>\n",
       "      <td>5.171300e+04</td>\n",
       "      <td>5.171300e+04</td>\n",
       "      <td>5.171300e+04</td>\n",
       "      <td>7.217700e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1990.263154</td>\n",
       "      <td>155.618915</td>\n",
       "      <td>1.920772e+07</td>\n",
       "      <td>1.352875e+07</td>\n",
       "      <td>1.004860e+07</td>\n",
       "      <td>1.984737e+06</td>\n",
       "      <td>3.072609e+07</td>\n",
       "      <td>7.792960e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.018761</td>\n",
       "      <td>390.261979</td>\n",
       "      <td>1.685819e+08</td>\n",
       "      <td>1.294180e+08</td>\n",
       "      <td>1.081375e+08</td>\n",
       "      <td>1.730488e+07</td>\n",
       "      <td>3.989630e+08</td>\n",
       "      <td>7.455443e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1961.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.876963e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1977.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>3.581080e-01</td>\n",
       "      <td>1.948302e-01</td>\n",
       "      <td>8.005409e-02</td>\n",
       "      <td>3.786298e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.894023e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1991.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>3.251810e+00</td>\n",
       "      <td>9.978667e+00</td>\n",
       "      <td>6.154094e+00</td>\n",
       "      <td>2.044437e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.292253e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2004.000000</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>3.610817e+06</td>\n",
       "      <td>1.734192e+06</td>\n",
       "      <td>9.450000e+05</td>\n",
       "      <td>3.867180e+05</td>\n",
       "      <td>1.915736e+01</td>\n",
       "      <td>1.532959e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2016.000000</td>\n",
       "      <td>5001.000000</td>\n",
       "      <td>3.984702e+09</td>\n",
       "      <td>3.417089e+09</td>\n",
       "      <td>2.979605e+09</td>\n",
       "      <td>4.726163e+08</td>\n",
       "      <td>1.257160e+10</td>\n",
       "      <td>2.061182e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               year  country_code     crop_land  grazing_land  fishing_ground  \\\n",
       "count  72186.000000  72186.000000  5.171400e+04  5.171400e+04    5.171300e+04   \n",
       "mean    1990.263154    155.618915  1.920772e+07  1.352875e+07    1.004860e+07   \n",
       "std       16.018761    390.261979  1.685819e+08  1.294180e+08    1.081375e+08   \n",
       "min     1961.000000      1.000000  0.000000e+00  0.000000e+00    0.000000e+00   \n",
       "25%     1977.000000     59.000000  3.581080e-01  1.948302e-01    8.005409e-02   \n",
       "50%     1991.000000    121.000000  3.251810e+00  9.978667e+00    6.154094e+00   \n",
       "75%     2004.000000    193.000000  3.610817e+06  1.734192e+06    9.450000e+05   \n",
       "max     2016.000000   5001.000000  3.984702e+09  3.417089e+09    2.979605e+09   \n",
       "\n",
       "       built_up_land        carbon         total  \n",
       "count   5.171300e+04  5.171300e+04  7.217700e+04  \n",
       "mean    1.984737e+06  3.072609e+07  7.792960e+07  \n",
       "std     1.730488e+07  3.989630e+08  7.455443e+08  \n",
       "min     0.000000e+00  0.000000e+00  1.876963e-02  \n",
       "25%     3.786298e-02  0.000000e+00  1.894023e+00  \n",
       "50%     2.044437e-01  0.000000e+00  8.292253e+03  \n",
       "75%     3.867180e+05  1.915736e+01  1.532959e+07  \n",
       "max     4.726163e+08  1.257160e+10  2.061182e+10  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://query.data.world/s/wh6j7rxy2hvrn4ml75ci62apk5hgae', low_memory=False)\n",
    "#describe the dataset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>country_code</th>\n",
       "      <th>record</th>\n",
       "      <th>crop_land</th>\n",
       "      <th>grazing_land</th>\n",
       "      <th>forest_land</th>\n",
       "      <th>fishing_ground</th>\n",
       "      <th>built_up_land</th>\n",
       "      <th>carbon</th>\n",
       "      <th>total</th>\n",
       "      <th>QScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>1992</td>\n",
       "      <td>1</td>\n",
       "      <td>AreaPerCap</td>\n",
       "      <td>0.140292</td>\n",
       "      <td>0.199546</td>\n",
       "      <td>0.097188051</td>\n",
       "      <td>0.036888</td>\n",
       "      <td>0.029320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.032351e-01</td>\n",
       "      <td>3A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>1992</td>\n",
       "      <td>1</td>\n",
       "      <td>AreaTotHA</td>\n",
       "      <td>483000.000000</td>\n",
       "      <td>687000.000000</td>\n",
       "      <td>334600</td>\n",
       "      <td>127000.000000</td>\n",
       "      <td>100943.000800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.732543e+06</td>\n",
       "      <td>3A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>1992</td>\n",
       "      <td>1</td>\n",
       "      <td>BiocapPerCap</td>\n",
       "      <td>0.159804</td>\n",
       "      <td>0.135261</td>\n",
       "      <td>0.084003213</td>\n",
       "      <td>0.013742</td>\n",
       "      <td>0.033398</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.262086e-01</td>\n",
       "      <td>3A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>1992</td>\n",
       "      <td>1</td>\n",
       "      <td>BiocapTotGHA</td>\n",
       "      <td>550176.242700</td>\n",
       "      <td>465677.972200</td>\n",
       "      <td>289207.1078</td>\n",
       "      <td>47311.551720</td>\n",
       "      <td>114982.279300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.467355e+06</td>\n",
       "      <td>3A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>1992</td>\n",
       "      <td>1</td>\n",
       "      <td>EFConsPerCap</td>\n",
       "      <td>0.387510</td>\n",
       "      <td>0.189462</td>\n",
       "      <td>1.26E-06</td>\n",
       "      <td>0.004165</td>\n",
       "      <td>0.033398</td>\n",
       "      <td>1.114093</td>\n",
       "      <td>1.728629e+00</td>\n",
       "      <td>3A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country  year  country_code        record      crop_land   grazing_land  \\\n",
       "0  Armenia  1992             1    AreaPerCap       0.140292       0.199546   \n",
       "1  Armenia  1992             1     AreaTotHA  483000.000000  687000.000000   \n",
       "2  Armenia  1992             1  BiocapPerCap       0.159804       0.135261   \n",
       "3  Armenia  1992             1  BiocapTotGHA  550176.242700  465677.972200   \n",
       "4  Armenia  1992             1  EFConsPerCap       0.387510       0.189462   \n",
       "\n",
       "   forest_land  fishing_ground  built_up_land    carbon         total QScore  \n",
       "0  0.097188051        0.036888       0.029320  0.000000  5.032351e-01     3A  \n",
       "1       334600   127000.000000  100943.000800  0.000000  1.732543e+06     3A  \n",
       "2  0.084003213        0.013742       0.033398  0.000000  4.262086e-01     3A  \n",
       "3  289207.1078    47311.551720  114982.279300  0.000000  1.467355e+06     3A  \n",
       "4     1.26E-06        0.004165       0.033398  1.114093  1.728629e+00     3A  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print the first five rows of the table\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3A    51473\n",
       "2A      240\n",
       "Name: QScore, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check distribution of target variable\n",
    "df['QScore'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country           0\n",
       "year              0\n",
       "country_code      0\n",
       "record            0\n",
       "crop_land         0\n",
       "grazing_land      0\n",
       "forest_land       0\n",
       "fishing_ground    0\n",
       "built_up_land     0\n",
       "carbon            0\n",
       "total             0\n",
       "QScore            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the rows with missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country           0\n",
       "year              0\n",
       "country_code      0\n",
       "record            0\n",
       "crop_land         0\n",
       "grazing_land      0\n",
       "forest_land       0\n",
       "fishing_ground    0\n",
       "built_up_land     0\n",
       "carbon            0\n",
       "total             0\n",
       "QScore            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for simplicity, the rows with missing values is dropped\n",
    "df = df.dropna()\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3A    51473\n",
       "2A      240\n",
       "Name: QScore, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''An obvious change in our target variable after removing the missing values is that there are only three classes left\n",
    "and from the distribution of the three classes there is an imbalance between the classes. There are methods to handle this\n",
    "imbalance, such as oversampling and undersampling.\n",
    "'''\n",
    "#Oversampling involves increasing the number of instances in the class with fewer instances. While undersampling involves reducing the data points in the class with more instances\n",
    "#For this example it will be converted to a binary classification problem by combining class '1A' and '2A'\n",
    "\n",
    "df['QScore'] = df['QScore'].replace(['1A'], '2A')\n",
    "df['QScore'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2A = df[df.QScore=='2A']\n",
    "df_3A = df[df.QScore=='3A'].sample(350)\n",
    "data_df = df_2A.append(df_3A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.utils\n",
    "data_df = sklearn.utils.shuffle(data_df)\n",
    "data_df = data_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3A    350\n",
       "2A    240\n",
       "Name: QScore, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.QScore.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#more processing\n",
    "data_df = data_df.drop(columns=['country_code', 'country', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_df.drop(columns='QScore')\n",
    "y = data_df['QScore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3A    247\n",
       "2A    166\n",
       "Name: QScore, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda\\lib\\site-packages\\pandas\\core\\generic.py:5303: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "#encode categorical variable\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "X_train.record = encoder.fit_transform(X_train.record)\n",
    "X_test.record = encoder.transform(X_test.record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=1)\n",
    "X_train_balanced, y_balanced = smote.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "normalised_train_df = scaler.fit_transform(X_train_balanced.drop(columns=['record']))\n",
    "normalised_train_df=pd.DataFrame(normalised_train_df, \n",
    " columns=X_train_balanced.drop(columns=[ 'record' ]).columns)\n",
    "normalised_train_df[ 'record' ]=X_train_balanced[ 'record']\n",
    "\n",
    "X_test=X_test.reset_index(drop=True)\n",
    "normalised_test_df=scaler.transform(X_test.drop(columns=['record']))\n",
    "normalised_test_df=pd.DataFrame(normalised_test_df, columns=X_test.drop(columns=['record']).columns)\n",
    "normalised_test_df['record']=X_test['record']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(penalty=12, solver='lbfigs')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg=LogisticRegression()\n",
    "log_reg.fit(normalised_train_df, y_balanced)\n",
    "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=100, multi_class='auto', n_jobs=None, penalty=12, random_state=None, solver='lbfigs', tol=0.0001, verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring Classification Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.43289689 0.54471129 0.51251964 0.49448529 0.47198276]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores=cross_val_score(log_reg, normalised_train_df, y_balanced, cv=5, scoring='f1_macro')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KFold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "kf=KFold(n_splits=5)\n",
    "kf.split(normalised_train_df)\n",
    "#create ans empty list\n",
    "f1_scores = []\n",
    "for train_index, test_index in kf.split(normalised_train_df):\n",
    "    x_train, x_test = normalised_train_df.iloc[train_index], normalised_train_df.iloc[test_index]\n",
    "    y_train, y_test = y_balanced[train_index], y_balanced[test_index]\n",
    "model = LogisticRegression().fit(x_train, y_train)\n",
    "#save result to the list\n",
    "f1_scores.append(f1_score(y_true=y_test, y_pred=model.predict(x_test), pos_label='2A')*100)\n",
    "#print the list\n",
    "print(f1_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[65.21739130434783]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "#create an empty list\n",
    "f1_scores = []\n",
    "#run for every split\n",
    "for train_index, test_index in skf.split(normalised_train_df, y_balanced):\n",
    "    x_train, x_test = np.array(normalised_train_df)[train_index], np.array(normalised_train_df)[test_index]\n",
    "    y_train, y_test = y_balanced[train_index], y_balanced[test_index]\n",
    "model = LogisticRegression().fit(x_train, y_train)\n",
    "#save result to the list\n",
    "f1_scores.append(f1_score(y_true=y_test, y_pred=model.predict(x_test), pos_label='2A') * 100)\n",
    "#print the list\n",
    "f1_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave One Out Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.93927125506073\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "loo = LeaveOneOut()\n",
    "scores = cross_val_score(LogisticRegression(), normalised_train_df, y_balanced, cv=loo, scoring='f1_macro')\n",
    "average_score = scores.mean() * 100\n",
    "print(average_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[46, 28],\n",
       "       [67, 36]], dtype=int64)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the necessary libraries\n",
    "from sklearn.metrics import  recall_score, accuracy_score, precision_score, confusion_matrix\n",
    "new_predictions = log_reg.predict(normalised_test_df)\n",
    "conf_mat = confusion_matrix(y_true=y_test, y_pred=new_predictions, labels=['2A', '3A'])\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 46\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_true=y_test, y_pred=new_predictions)\n",
    "print(\"Accuracy: {}\".format(round(accuracy*100), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 46\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(y_true=y_test, y_pred=new_predictions, pos_label='2A')\n",
    "print(\"Precision: {}\".format(round(accuracy*100), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 62\n"
     ]
    }
   ],
   "source": [
    "recall_score = recall_score(y_true=y_test, y_pred=new_predictions, pos_label='2A')\n",
    "print(\"Recall: {}\".format(round(recall_score*100), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1:49\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(y_true=y_test, y_pred=new_predictions, pos_label='2A')\n",
    "print( 'F1:{}'.format(round(f1* 100 ),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying a decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dec_tree = DecisionTreeClassifier()\n",
    "dec_tree_model = dec_tree.fit(normalised_train_df, y_balanced)\n",
    "dec_tree_prediction = dec_tree_model.predict(normalised_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.56286796 0.57536765 0.59549502 0.51556481 0.53564738]\n"
     ]
    }
   ],
   "source": [
    "#measuring the performance of the decission tree classifier\n",
    "cv_score = cross_val_score(dec_tree, normalised_train_df, y_balanced, cv=5, scoring='f1_macro')\n",
    "print(cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for the decision tree: 47\n"
     ]
    }
   ],
   "source": [
    "#getting the f1 Score of the decision tree classifier\n",
    "dec_tree_f1_score = f1_score(y_true=y_test, y_pred=dec_tree_prediction, pos_label='2A')\n",
    "print(\"F1 Score for the decision tree: {}\".format(round(dec_tree_f1_score*100), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
